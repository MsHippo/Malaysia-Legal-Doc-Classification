{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8112650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re, nltk\n",
    "import PyPDF2\n",
    "import pickle\n",
    "import pdftotext\n",
    "import string\n",
    "import sys\n",
    "import fileinput\n",
    "from pathlib import Path\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb09a67",
   "metadata": {},
   "source": [
    "# Extract the data from the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b62a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read folder into folder\n",
    "def read_pdf(file_path):\n",
    "    #     file_path = str(input(\"Enter training directory path: \\n\"))\n",
    "    files_list = []\n",
    "    # PDF documents filepath\n",
    "    for root, dirs, files in os.walk(file_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):  # read all file end with pdf\n",
    "                # store the read file name into a list\n",
    "                files_list.append(os.path.join(root, file))\n",
    "    return files_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2cad6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_folder_file(parent_dir, directory,  file_name, pdf):\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "#     print(\"Directory '% s' created\" % path)\n",
    "#     print(\"file_name '% s' created\" % file_name)\n",
    "#     file_name = head_list[8]\n",
    "#     new_files_path = path + \"/\"+ file_name +'.file'\n",
    "    new_files_path = path + \"/\" + file_name + '.txt'\n",
    "    # Save all text to a txt file.\n",
    "    with open(new_files_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\\n\".join(pdf))\n",
    "        print(\"Files '% s' created\" % file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7465089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the text from all pdf files in a specified directory\n",
    "def pdf_to_txt(folder, new_folder):\n",
    "    \n",
    "    for file in read_pdf(folder):\n",
    "        #     print(files_list)\n",
    "        content_data = \"\"\n",
    "        # Load your PDF, extract the content from pdf\n",
    "        # Do data cleaning here\n",
    "        with open(file, \"rb\") as f:\n",
    "            pdf = pdftotext.PDF(f)\n",
    "        head, tail = os.path.splitext(file)\n",
    "        head_list = head.split(os.sep)\n",
    "        store_folder_file(new_folder, head_list[7], head_list[8], pdf)\n",
    "        # print(f\"{new_folder}, new_folder_type = {type(new_folder)}, {dir}, {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "984329ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "# Extracts the text from all pdf files in a specified directory\n",
    "def pdf_to_txt_exp(folder):\n",
    "\n",
    "    for file in read_pdf(folder):\n",
    "        #     print(files_list)\n",
    "        content_data = \"\"\n",
    "        # Load your PDF, extract the content from pdf\n",
    "        with open(file, \"rb\") as f:\n",
    "            pdf = pdftotext.PDF(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9855ee",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b714da",
   "metadata": {},
   "source": [
    "if the tasks require full sentence structure, like next word prediction or grammar check, this step can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "412a4f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\heihe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\heihe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\heihe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')  # it is one time execution\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_remove_stp(text):\n",
    "    try:\n",
    "       word_tokens = word_tokenize(text)\n",
    "       filtered_word = [w for w in word_tokens if not w in stop_words]\n",
    "       filtered_word = [w + \" \" for w in filtered_word]\n",
    "       return filtered_word\n",
    "    except:\n",
    "       return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6578788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condenses all repeating newline characters into one single newline character\n",
    "def text_processing(text):\n",
    "    #removing extra line\n",
    "    content = '\\n'.join([p for p in re.split('\\n|\\r', text) if len(p) > 0])\n",
    "\n",
    "    #case normalization & removing punctuations using set\n",
    "    content = content.lower()\n",
    "    # trivial way of regex for punctuation\n",
    "    p_punct = re.compile(f\"[{string.punctuation}]\")\n",
    "    content = re.sub(p_punct, \"\", content)\n",
    "\n",
    "    # content = ''.join([i.lower()\n",
    "    #                   for i in content if i not in string.punctuation])\n",
    "\n",
    "    #tokenize and remove the stopwords\n",
    "    content_new = tokenize_remove_stp(content)\n",
    "\n",
    "    #Lemmatize the text\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_lemm = [lemmatizer.lemmatize(word) for word in content_new]\n",
    "    join_word_lemm = \" \".join(word_lemm)\n",
    "    return join_word_lemm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04cf5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_write_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r+', encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        with open(file_path, \"w+\", encoding=\"utf-8\") as f:\n",
    "            f.write(text_processing(text))\n",
    "        print(\"Cleaned text\", file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "852b1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(path):\n",
    "    #     file_path = str(input(\"Enter training directory path: \\n\"))\n",
    "    # PDF documents filepath\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            # read all file end with pdf\n",
    "            if file.endswith(\".txt\"):\n",
    "                # store the read file name into a list\n",
    "                file_path = f\"{root}\\{file}\"\n",
    "                read_write_text_file(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a37dc",
   "metadata": {},
   "source": [
    "folder = r'C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\combinned_data_txt'\n",
    "print (read_doc(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "096eca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:', 'Users', 'heihe', 'Desktop', 'Malaysia-Legal-Doc-Classification', 'code_revised', 'training_data_pdf', 'Abetment', 'CLJ_2003_4_409_psb']\n",
      "0= C:\n",
      "1= Users\n",
      "2= heihe\n",
      "3= Desktop\n",
      "4= Malaysia-Legal-Doc-Classification\n",
      "5= code_revised\n",
      "6= training_data_pdf\n",
      "7= Abetment\n",
      "8= CLJ_2003_4_409_psb\n",
      "Files 'CLJ_2003_4_409_psb' created\n",
      "Files 'CLJ_2010_2_1_psb' created\n",
      "Files 'LNS_2017_1_781_psb' created\n",
      "Files 'CLJ_2019_4_705_psb' created\n",
      "Files 'CLJ_2019_4_723_psb' created\n",
      "Files 'CLJ_2019_4_799_psb' created\n",
      "Files 'CLJ_2019_5_23_psb' created\n",
      "Files 'CLJ_2019_5_293_psb' created\n",
      "Files 'CLJ_2019_5_355_psb' created\n",
      "Files 'CLJ_2019_5_93_psb' created\n",
      "Files 'CLJ_2019_6_561_psb' created\n",
      "Files 'CLJ_2015_8_329_psb' created\n",
      "Files 'CLJ_2018_3_662_psb' created\n",
      "Files 'CLJ_2018_5_326_psb' created\n",
      "Files 'LNS_2015_1_1208_psb' created\n",
      "Files 'LNS_2015_1_668_psb' created\n",
      "Files 'LNS_2017_1_164_psb' created\n",
      "Files 'LNS_2017_1_1804_psb' created\n",
      "Files 'CLJ_2017_10_1_psb' created\n",
      "Files 'CLJ_2018_4_236_psb' created\n",
      "Files 'CLJ_2019_1_748_psb' created\n",
      "Files 'CLJ_2019_3_325_psb' created\n",
      "Files 'LNS_2018_1_520_psb' created\n",
      "Files 'CLJ_2018_6_257_psb' created\n",
      "Files 'CLJ_2018_7_501_psb' created\n",
      "Files 'CLJ_2019_2_772_psb' created\n",
      "Files 'CLJ_2019_5_780_psb' created\n",
      "Files 'LNS_2017_1_2044_psb' created\n",
      "Files 'LNS_2017_1_2045_psb' created\n",
      "Files 'LNS_2017_1_54_psb' created\n",
      "Files 'LNS_2018_1_371_psb' created\n",
      "Files 'CLJ_2012_10_96_psb' created\n",
      "Files 'CLJ_2013_9_287_psb' created\n",
      "Files 'CLJ_2015_2_889_psb' created\n",
      "Files 'LNS_2017_1_1322_psb' created\n",
      "Files 'CLJ_2013_4_613_psb' created\n",
      "Files 'CLJ_2013_5_751_psb' created\n",
      "Files 'CLJ_2013_8_834_psb' created\n",
      "Files 'CLJ_2015_4_446_psb' created\n",
      "Files 'CLJ_2015_6_464_psb' created\n",
      "Files 'LNS_2012_1_603_psb' created\n",
      "Files 'LNS_2013_1_1386_psb' created\n",
      "Files 'LNS_2016_1_1067_psb' created\n",
      "Files 'CLJ_2014_6_110_psb' created\n",
      "Files 'CLJ_2015_1_678_psb' created\n",
      "Files 'CLJ_2019_5_339_psb' created\n",
      "Files 'CLJ_2017_5_44_psb' created\n",
      "Files 'CLJ_2017_7_703_psb' created\n",
      "Files 'CLJ_2018_3_681_psb' created\n",
      "Files 'CLJ_2018_4_110_psb' created\n",
      "Files 'CLJ_2018_6_436_psb' created\n",
      "Files 'LNS_2017_1_1010_psb' created\n",
      "Files 'CLJ_2018_10_562_psb' created\n",
      "Files 'CLJ_2018_10_597_psb' created\n",
      "Files 'CLJ_2018_9_265_psb' created\n",
      "Files 'CLJ_2019_1_526_psb' created\n",
      "Files 'CLJ_2006_5_345_psb' created\n",
      "Files 'LNS_2000_1_9_psb' created\n",
      "Files 'CLJ_2014_6_134_psb' created\n",
      "Files 'CLJ_2016_8_15_psb' created\n",
      "Files 'CLJ_2017_4_91_psb' created\n",
      "Files 'CLJ_2018_10_742_psb' created\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Abetment\\CLJ_2003_4_409_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Abetment\\CLJ_2010_2_1_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Abetment\\LNS_2017_1_781_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Charges\\CLJ_2019_4_705_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Charges\\CLJ_2019_4_723_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Charges\\CLJ_2019_4_799_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Charges\\CLJ_2019_5_23_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Charges\\CLJ_2019_5_293_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Charges\\CLJ_2019_5_355_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Charges\\CLJ_2019_5_93_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Charges\\CLJ_2019_6_561_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Common intention\\CLJ_2015_8_329_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Common intention\\CLJ_2018_3_662_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Common intention\\CLJ_2018_5_326_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Common intention\\LNS_2015_1_1208_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Common intention\\LNS_2015_1_668_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Common intention\\LNS_2017_1_164_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Common intention\\LNS_2017_1_1804_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Corruption\\CLJ_2017_10_1_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Corruption\\CLJ_2018_4_236_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Corruption\\CLJ_2019_1_748_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Corruption\\CLJ_2019_3_325_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Corruption\\LNS_2018_1_520_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Dangerous Drugs\\CLJ_2018_6_257_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Dangerous Drugs\\CLJ_2018_7_501_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Dangerous Drugs\\CLJ_2019_2_772_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Dangerous Drugs\\CLJ_2019_5_780_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Dangerous Drugs\\LNS_2017_1_2044_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Dangerous Drugs\\LNS_2017_1_2045_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Dangerous Drugs\\LNS_2017_1_54_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Dangerous Drugs\\LNS_2018_1_371_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Defence\\CLJ_2012_10_96_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Defence\\CLJ_2013_9_287_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Defence\\CLJ_2015_2_889_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Defence\\LNS_2017_1_1322_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Firearms\\CLJ_2013_4_613_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Firearms\\CLJ_2013_5_751_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Firearms\\CLJ_2013_8_834_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Firearms\\CLJ_2015_4_446_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Firearms\\CLJ_2015_6_464_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Firearms\\LNS_2012_1_603_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Firearms\\LNS_2013_1_1386_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Firearms\\LNS_2016_1_1067_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Money Laundering\\CLJ_2014_6_110_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Money Laundering\\CLJ_2015_1_678_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Money Laundering\\CLJ_2019_5_339_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Murder\\CLJ_2017_5_44_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Murder\\CLJ_2017_7_703_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Murder\\CLJ_2018_3_681_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Murder\\CLJ_2018_4_110_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Murder\\CLJ_2018_6_436_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Murder\\LNS_2017_1_1010_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Offences\\CLJ_2018_10_562_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Offences\\CLJ_2018_10_597_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Offences\\CLJ_2018_9_265_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Offences\\CLJ_2019_1_526_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Rape\\CLJ_2006_5_345_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Rape\\LNS_2000_1_9_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Sedition\\CLJ_2014_6_134_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Sedition\\CLJ_2016_8_15_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Sedition\\CLJ_2017_4_91_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\training_data_txt\\Sedition\\CLJ_2018_10_742_psb.txt\n",
      "None\n",
      "['C:', 'Users', 'heihe', 'Desktop', 'Malaysia-Legal-Doc-Classification', 'code_revised', 'testing_data_pdf', 'Abetment', 'CLJ_2012_1_358_psb']\n",
      "0= C:\n",
      "1= Users\n",
      "2= heihe\n",
      "3= Desktop\n",
      "4= Malaysia-Legal-Doc-Classification\n",
      "5= code_revised\n",
      "6= testing_data_pdf\n",
      "7= Abetment\n",
      "8= CLJ_2012_1_358_psb\n",
      "Files 'CLJ_2012_1_358_psb' created\n",
      "Files 'CLJ_2019_5_165_psb' created\n",
      "Files 'CLJ_2019_5_217_psb' created\n",
      "Files 'LNS_2016_1_1067_psb' created\n",
      "Files 'LNS_2017_1_46_psb' created\n",
      "Files 'LNS_2017_1_2103_psb' created\n",
      "Files 'LNS_2018_1_240_psb' created\n",
      "Files 'LNS_2017_1_1090_psb' created\n",
      "Files 'LNS_2017_1_1804_psb' created\n",
      "Files 'CLJ_2019_6_325_psb' created\n",
      "Files 'CLJ_2015_10_48_psb' created\n",
      "Files 'CLJ_2018_10_628_psb' created\n",
      "Files 'CLJ_2018_8_327_psb' created\n",
      "Files 'CLJ_2018_10_36_psb' created\n",
      "Files 'LNS_2017_1_781_psb' created\n",
      "Files 'CLJ_2019_3_360_psb' created\n",
      "Files 'CLJ_2019_3_360_psb' created\n",
      "Files 'CLJ_2018_3_1_psb' created\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Abetment\\CLJ_2012_1_358_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Charges\\CLJ_2019_5_165_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Charges\\CLJ_2019_5_217_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Common intention\\LNS_2016_1_1067_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Common intention\\LNS_2017_1_46_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Corruption\\LNS_2017_1_2103_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Corruption\\LNS_2018_1_240_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Dangerous Drugs\\LNS_2017_1_1090_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Dangerous Drugs\\LNS_2017_1_1804_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Defence\\CLJ_2019_6_325_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Firearms\\CLJ_2015_10_48_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Firearms\\CLJ_2018_10_628_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Money Laundering\\CLJ_2018_8_327_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Murder\\CLJ_2018_10_36_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Murder\\LNS_2017_1_781_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Offences\\CLJ_2019_3_360_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Rape\\CLJ_2019_3_360_psb.txt\n",
      "Cleaned text C:\\Users\\heihe\\Desktop\\Malaysia-Legal-Doc-Classification\\code_revised\\testing_data_txt\\Sedition\\CLJ_2018_3_1_psb.txt\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    training_files_path = str(\n",
    "        input(\"Enter training corpus directory path: \\n\"))\n",
    "    testing_files_path = str(\n",
    "        input(\"Enter testing corpus directory path: \\n\"))\n",
    "    training_head_collection = []\n",
    "    testing_head_collection = []\n",
    "\n",
    "    #Training data set\n",
    "    #get the correct index number to create correct file name\n",
    "    for file in read_pdf(training_files_path):\n",
    "        head, tail = os.path.splitext(file)\n",
    "        training_head_collection.append(head)\n",
    "\n",
    "    head_list = training_head_collection[0].split(os.sep)\n",
    "    print(head_list)\n",
    "    for i in range(len(head_list)):\n",
    "        print(f\"{i}= {head_list[i]}\")\n",
    "\n",
    "    training_data_dir = str(input(\"Training directory with folder name to content txt: \"))\n",
    "    \n",
    "    #create the folder if the folder does not exit\n",
    "    Path(training_data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    pdf_to_txt(training_files_path, training_data_dir)\n",
    "\n",
    "    #do the data processing of the text file\n",
    "    print(read_doc(training_data_dir))\n",
    "\n",
    "    #Testing data set\n",
    "    for file in read_pdf(testing_files_path):\n",
    "        head, tail = os.path.splitext(file)\n",
    "        testing_head_collection.append(head)\n",
    "\n",
    "    head_list = testing_head_collection[0].split(os.sep)\n",
    "    print(head_list)\n",
    "    for i in range(len(head_list)):\n",
    "        print(f\"{i}= {head_list[i]}\")\n",
    "\n",
    "    testing_data_dir = str(\n",
    "        input(\"Testing directory with folder name to content txt: \"))\n",
    "\n",
    "    #create the folder if the folder does not exit\n",
    "    Path(testing_data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    pdf_to_txt(testing_files_path, testing_data_dir)\n",
    "\n",
    "    #do the data processing of the text file\n",
    "    print(read_doc(testing_data_dir))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
